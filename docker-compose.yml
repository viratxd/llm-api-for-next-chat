services:
  llm-api-for-next-chat:
    build: .
    image: llm-api-for-next-chat/llm-api-for-next-chat:latest
    container_name: llm-api-for-next-chat
    ports:
      - 5000:5000
    restart: unless-stopped
    volumes:
      - ./chatgpt_web/file_cache.json:/app/chatgpt_web/file_cache.json
      - ./theb_ai/Theb_API.json:/app/theb_ai/Theb_API.json
      - ./hugging_chat/config.json:/app/hugging_chat/config.json
      - ./generated_images:/app/generated_images
      - .env:/app/.env
      - ./docker-compose.yml:/app/docker-compose.yml
      - ./scripts:/app/scripts
    networks:
      - llms_api

  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web
    container_name: chatgpt-next-web
    restart: unless-stopped
    ports:
      - 3030:3000
    environment:
      BASE_URL: http://llm-api-for-next-chat:5000/api/openai
      ANTHROPIC_URL: http://llm-api-for-next-chat:5000/api/anthropic
      CUSTOM_MODELS: "-all,\
        o1-preview@OpenAI,\
        o1-mini@OpenAI,\
        gpt-4o@OpenAI,\
        gpt-4o-mini@OpenAI,\
        gpt-4@OpenAI,\
        gpt-3.5@OpenAI,\
        gemma-2-27b@Gemma,\
        gemma-2-9b@Gemma,\
        learnlm-1.5-pro-experimental@Google,\
        gemini-exp-1206@Google,\
        gemini-1.5-pro-latest@Google,\
        gemini-2.0-flash-thinking-exp-1219@Google,\
        gemini-2.0-flash-exp@Google,\
        gemini-1.5-flash-latest@Google,\
        gemini-1.5-flash-8b-latest@Google,\
        claude-3-5-sonnet-20240620@Anthropic,\
        claude-3-opus-20240229@Anthropic,\
        claude-3-sonnet-20240229@Anthropic,\
        claude-3-haiku-20240307@Anthropic,\
        llama-3.1-405b@Meta,\
        llama-3.1-70b@Meta,\
        llama-3.1-8b@Meta,\
        llama-3-70b@Meta,\
        llama-3-8b@Meta,\
        mixtral-8x22b@MistralAI,\
        mixtral-8x7b@MistralAI,\
        mistral-7b@MistralAI,\
        wizardlm-2-8x22b@WizardLM,\
        dbrx-instruct@Databricks,\
        qwen-2-72b@Qwen,\
        qwen-1.5-110b@Qwen,\
        qwen-1.5-72b@Qwen,\
        qwen-1.5-32b@Qwen,\
        qwen-1.5-14b@Qwen,\
        qwen-1.5-7b@Qwen,\
        deepseek-llm-67b@DeepSeek,\
        deepseek-v2.5@DeepSeek,\
        yi-34b@01.AI,\
        theb-ai@TheB.AI,\
        qwen2.5-72b-instruct@Qwen,\
        llama-3.3-70b-instruct@Meta,\
        c4ai-command-r-plus-08-2024@CohereForAI,\
        qwq-32b-preview@Qwen,\
        llama-3.1-nemotron-70b-instruct-hf@Meta,\
        qwen2.5-coder-32b-instruct@Qwen,\
        llama-3.2-11b-vision-instruct@Meta,\
        hermes-3-llama-3.1-8b@Meta,\
        mistral-nemo-instruct-2407@MistralAI,\
        phi-3.5-mini-instruct@Microsoft"
    env_file:
      - .env
    networks:
      - llms_api

  monitor:
    image: docker:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./docker-compose.yml:/app/docker-compose.yml
      - .env:/app/.env
      - ./scripts:/app/scripts
    command: sh -c "chmod +x /app/scripts/monitor.sh && /app/scripts/monitor.sh"
    depends_on:
      - llm-api-for-next-chat
    networks:
      - llms_api

networks:
  llms_api:
    name: llms_api
